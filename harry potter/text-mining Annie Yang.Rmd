---
title: "Text Analyis"
output: github_document
---




# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
    ```
    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
    ```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
- Ask questions about the data
- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 

```{r}
install.packages("devtools")
library(devtools)
```

```{r}
devtools::install_github("bradleyboehmke/harrypotter")
```

```{r}
install.packages("tidytext")
library(tidytext)
```

```{r}
install.packages("stringr")
library(stringr)
stone<-harrypotter::philosophers_stone
```

```{r}
install.packages("dplyr")
library(dplyr)
```

```{r}
stone_df<-data_frame(chapter=1:17,text=stone)
tidy_stone<-stone_df%>%unnest_tokens(word,text)

# Remove stop words
data(stop_words)
tidy_stone<-tidy_stone%>%anti_join(stop_words)

# Find the most common words in the book
tidy_stone%>%count(word,sort=T)%>%rename(freq_w=n)
# The results make sense. Of course, Harry is the most frequently used word in the book.
```

```{r}
# Visualize the most common words
install.packages("ggplot2")
library(ggplot2)
tidy_stone %>% 
  count(word,sort=T)%>%
  filter(n > 100) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

```{r}
# What are the most joy words in the book?
nrcjoy<-get_sentiments("nrc")%>%filter(sentiment=="joy")
tidy_stone%>%inner_join(nrcjoy)%>%count(word,sort=T)%>%rename(joyword=word)

# What are the most sad words in the book?
nrcsad<-get_sentiments("nrc")%>%filter(sentiment=="sadness")
tidy_stone%>%inner_join(nrcsad)%>%count(word,sort=T)%>%rename(sadword=word)
# We should ignore harry in the sadword column
```

```{r}
# Examine how sentiment changes throughout the book
# Count the negative and positive words appearing in each chapters
sent_c<-tidy_stone%>%inner_join(get_sentiments("bing"))%>%group_by(chapter)%>%count(sentiment,sort=T)
ggplot(sent_c,aes(chapter,n,color=sentiment))+
geom_line()+
ylab("frequency") 
# According to the chart, we find that in each chapter negative words are used more frequently than positive words
```

